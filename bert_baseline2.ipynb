{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8fghqT-Ukxv"
   },
   "outputs": [],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj5ev1pTVn2Z"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745292976539,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "rcyAKSViWb-Y"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745292976737,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "G08h8sA9Wj9w"
   },
   "outputs": [],
   "source": [
    "def connect_4o(input):\n",
    "  client = OpenAI(api_key=\"\")\n",
    "\n",
    "  response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"input_text\",\n",
    "          \"text\": \"Your job is to clearly and directly explain the thought process of a decision-making process.\\n \\nThe uploaded JSON file contains data stored within an autonomous driving system, specifically designed to plan the future trajectory of ego agent based on the information of environment.\\n \\nDetails of the file format:\\nThe data of surrounding agents contains the position, heading, and velocity, where ego agent makes its decision based upon.\\n \\nYou need to analyze and provide direct explanation of why system makes such suggestions for  ego agent based on the information stored in the json. Please answer the questions you are given directly without any introductory or concluding statements.\"\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": input\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    text={\n",
    "      \"format\": {\n",
    "        \"type\": \"text\"\n",
    "      }\n",
    "    },\n",
    "    reasoning={},\n",
    "    tools=[],\n",
    "    temperature=1,\n",
    "    max_output_tokens=2048,\n",
    "    top_p=1,\n",
    "    store=True\n",
    "  )\n",
    "\n",
    "  gpt_response_message_content = next((out.content[0].text for out in response.output if out.type == 'message'), None)\n",
    "\n",
    "  return gpt_response_message_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745292977163,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "CfqAtHeZWrba"
   },
   "outputs": [],
   "source": [
    "def connect_gpt_o1(input):\n",
    "  client = OpenAI(api_key=\"\")\n",
    "\n",
    "  response = client.responses.create(model=\"o1\", input=[\n",
    "    {\n",
    "      \"role\": \"developer\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Your job is to clearly and directly explain the thought process of a decision-making process.\\n \\nThe uploaded JSON file contains data stored within an autonomous driving system, specifically designed to plan the future trajectory of ego agent based on the information of environment.\\n \\nDetails of the file format:\\nThe data of surrounding agents contains the position, heading, and velocity, where ego agent makes its decision based upon.\\n \\nYou need to analyze and provide direct explanation of why system makes such suggestions for  ego agent based on the information stored in the json. Please answer the questions you are given directly without any introductory or concluding statements.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": input\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "    text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "    reasoning={\n",
    "    \"effort\": \"low\"\n",
    "  },\n",
    "    tools=[],\n",
    "    store=True\n",
    "  )\n",
    "\n",
    "  gpt_response_message_content = next((out.content[0].text for out in response.output if out.type == 'message'), None)\n",
    "\n",
    "  return gpt_response_message_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745292977605,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "q8aeaGEAW9J0"
   },
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "import torch\n",
    "\n",
    "def calculate_bertscore(generated_texts, reference_texts, lang=\"en\", model_type=None, device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"\n",
    "    Calculates the BERTScore (Precision, Recall, and F1) between generated and reference texts.\n",
    "\n",
    "    Args:\n",
    "        generated_texts (list of str): A list of generated sentences.\n",
    "        reference_texts (list of str or list of list of str): A list of reference sentences.\n",
    "                                                             If multiple references per generated text,\n",
    "                                                             provide a list of lists.\n",
    "        lang (str): The language of the texts (e.g., \"en\" for English).\n",
    "                    Required if model_type is not specified.\n",
    "        model_type (str, optional): The pre-trained BERT model to use (e.g., \"bert-base-uncased\").\n",
    "                                    If None, a default model for the specified language is used.\n",
    "        device (str, optional): The device to run the model on (\"cuda\" for GPU, \"cpu\" for CPU).\n",
    "                                Defaults to \"cuda:0\" if a GPU is available, otherwise \"cpu\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three torch.Tensor objects:\n",
    "               - precision: BERTScore Precision for each sentence.\n",
    "               - recall: BERTScore Recall for each sentence.\n",
    "               - f1: BERTScore F1 score for each sentence.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        P, R, F1 = score(generated_texts, reference_texts, lang=lang, model_type=model_type, device=device)\n",
    "        return P, R, F1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during BERTScore calculation: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1745292978197,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "jvgNA8j6h5YJ"
   },
   "outputs": [],
   "source": [
    "ref_gt = {}\n",
    "\n",
    "for filename in os.listdir(\"/content/drive/MyDrive/output_jsons_after_logical_calculation\"):\n",
    "  file_path = os.path.join(\"/content/drive/MyDrive/output_jsons_after_logical_calculation\", filename)\n",
    "  with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    key_feature = data.get(\"key_feature\")\n",
    "    ground_truth = data.get(\"ground_truth\")\n",
    "    # print(key_feature, quant_value, ground_truth)\n",
    "    # query = key_feature + \" \" + str(quant_value)\n",
    "    ref = key_feature + \" \" + str(ground_truth)\n",
    "    ref_gt[filename.split(\"_T\")[0]] = ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745292978681,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "V9FBFHGcj5It",
    "outputId": "7cf295b3-7ef5-4f06-d76f-c0dc781bd7c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene_0': 'observed position of agent_4 at scene time 20 at the 19 timestamp 4.15',\n",
       " 'scene_4': 'observed position of agent_4 at scene time 122 at the 19 timestamp 0.1',\n",
       " 'scene_3': 'observed position of agent_4 at scene time 122 at the 19 timestamp 9.85',\n",
       " 'scene_1': 'observed position of agent_4 at scene time 87 at the 19 timestamp 16.55',\n",
       " 'scene_7': 'observed position of agent_4 at scene time 120 at the 19 timestamp 5.02',\n",
       " 'scene_12': 'observed position of agent_4 at scene time 117 at the 19 timestamp 11.1',\n",
       " 'scene_13': 'observed position of agent_4 at scene time 117 at the 19 timestamp 12',\n",
       " 'scene_16': 'observed position of agent_4 at scene time 20 at the 19 timestamp 6.8',\n",
       " 'scene_17': 'observed position of agent_4 at scene time 22 at the 19 timestamp 0.05',\n",
       " 'scene_20': 'observed position of agent_4 at scene time 21 at the 19 timestamp 10.4',\n",
       " 'scene_21': 'observed position of agent_4 at scene time 111 at the 19 timestamp 3.9',\n",
       " 'scene_22': 'observed position of agent_4 at scene time 121 at the 19 timestamp 1.65',\n",
       " 'scene_23': 'observed position of agent_4 at scene time 22 at the 19 timestamp 0.05',\n",
       " 'scene_24': 'observed position of agent_4 at scene time 123 at the 19 timestamp 7',\n",
       " 'scene_26': 'observed position of agent_4 at scene time 103 at the 19 timestamp 14.7',\n",
       " 'scene_27': 'observed position of agent_4 at scene time 26 at the 19 timestamp 5',\n",
       " 'scene_28': 'observed position of agent_4 at scene time 120 at the 19 timestamp 0.8',\n",
       " 'scene_29': 'observed position of agent_4 at scene time 121 at the 19 timestamp 4.7',\n",
       " 'scene_31': 'observed position of agent_4 at scene time 123 at the 19 timestamp 0.7',\n",
       " 'scene_35': 'observed position of agent_4 at scene time 20 at the 19 timestamp 15.8',\n",
       " 'scene_40': 'observed position of agent_4 at scene time 20 at the 19 timestamp 8.7',\n",
       " 'scene_41': 'observed position of agent_4 at scene time 100 at the 19 timestamp 0.8',\n",
       " 'scene_42': 'observed position of agent_4 at scene time 23 at the 19 timestamp 4.2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745292980132,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "Pv3XN_JFj8Zp",
    "outputId": "f25d1a7f-0a3b-4a1f-b245-30070a17d149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scene_29\n",
      "scene_0\n",
      "scene_26\n",
      "scene_41\n",
      "scene_31\n",
      "scene_27\n",
      "scene_3\n",
      "scene_20\n",
      "scene_4\n",
      "scene_16\n",
      "scene_21\n",
      "scene_17\n",
      "scene_40\n",
      "scene_1\n",
      "scene_23\n",
      "scene_7\n",
      "scene_13\n",
      "scene_12\n",
      "scene_42\n",
      "scene_24\n",
      "scene_35\n",
      "scene_28\n",
      "scene_22\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(\"/content/drive/MyDrive/processed_data_new\"):\n",
    "  print(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1745293029920,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "N1xLyYBXWwdu"
   },
   "outputs": [],
   "source": [
    "def evaluate_4o_assistant_accuracy(folder_path):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                query = str(data[\"scene_data\"][\"general_data\"][\"observed_agents\"][\"front_camera\"]) + str(data[\"scene_data\"][\"general_data\"][\"ego_agent\"])\n",
    "                ref = ref_gt[filename.split(\".\")[0]]\n",
    "                output_1 = connect_4o(query)\n",
    "                output_2 = connect_4o(ref)\n",
    "                # print(output_1, output_2)\n",
    "                P, R, F1 = calculate_bertscore([output_1], [output_2])\n",
    "                total += F1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No valid files processed.\")\n",
    "        return 0.0\n",
    "    print(total)\n",
    "    accuracy = total/len(os.listdir(folder_path)) * 100\n",
    "    print(f\"Assistant Accuracy: {correct}/{total} = {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745293030095,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "9N28WaeLakf6"
   },
   "outputs": [],
   "source": [
    "def evaluate_o1_assistant_accuracy(folder_path):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                query = str(data[\"scene_data\"][\"general_data\"][\"observed_agents\"][\"front_camera\"]) + str(data[\"scene_data\"][\"general_data\"][\"ego_agent\"])\n",
    "                ref = ref_gt[filename.split(\".\")[0]]\n",
    "                output_1 = connect_gpt_o1(query)\n",
    "                output_2 = connect_gpt_o1(ref)\n",
    "                # print(output_1, output_2)\n",
    "                P, R, F1 = calculate_bertscore([output_1], [output_2])\n",
    "                total += F1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No valid files processed.\")\n",
    "        return 0.0\n",
    "\n",
    "    print(total)\n",
    "\n",
    "    accuracy = total/len(os.listdir(folder_path)) * 100\n",
    "    print(f\"Assistant Accuracy: {correct}/{total} = {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 761220,
     "status": "error",
     "timestamp": 1745294221938,
     "user": {
      "displayName": "Rex Chen",
      "userId": "03568709055767720474"
     },
     "user_tz": 300
    },
    "id": "9axi0ovmZqb_",
    "outputId": "bb24d3b2-3809-4941-9524-b5b0b2ffb5d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/24 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  8%|▊         | 2/24 [00:42<07:52, 21.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 12%|█▎        | 3/24 [01:18<09:36, 27.44s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|█▋        | 4/24 [01:53<10:06, 30.30s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 21%|██        | 5/24 [02:32<10:29, 33.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|██▌       | 6/24 [03:11<10:31, 35.10s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|██▉       | 7/24 [03:39<09:21, 33.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 33%|███▎      | 8/24 [04:09<08:32, 32.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 38%|███▊      | 9/24 [04:48<08:32, 34.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 42%|████▏     | 10/24 [05:19<07:43, 33.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 46%|████▌     | 11/24 [05:56<07:27, 34.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████     | 12/24 [06:31<06:52, 34.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 54%|█████▍    | 13/24 [07:01<06:04, 33.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 58%|█████▊    | 14/24 [07:26<05:06, 30.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 62%|██████▎   | 15/24 [08:01<04:47, 31.89s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 67%|██████▋   | 16/24 [08:36<04:24, 33.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 71%|███████   | 17/24 [09:12<03:55, 33.71s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|███████▌  | 18/24 [09:39<03:11, 31.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 79%|███████▉  | 19/24 [10:06<02:32, 30.43s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 83%|████████▎ | 20/24 [10:46<02:13, 33.28s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 88%|████████▊ | 21/24 [11:09<01:30, 30.27s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 92%|█████████▏| 22/24 [11:44<01:03, 31.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 96%|█████████▌| 23/24 [12:15<00:31, 31.34s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 24/24 [12:41<00:00, 31.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18.9554])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ad12e85ba9bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/processed_data_new\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maccuracy_4o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_o1_assistant_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# accuracy_o3 = evaluate_o3_assistant_accuracy(folder_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The accuracy of quantitative value calculation after the logical reasoning is: {accuracy_4o:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-7fb189f1b5e4>\u001b[0m in \u001b[0;36mevaluate_o1_assistant_accuracy\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Assistant Accuracy: {correct}/{total} = {accuracy:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    folder_path = \"/content/drive/MyDrive/processed_data_new\"\n",
    "    accuracy_4o = evaluate_o1_assistant_accuracy(folder_path)\n",
    "    # accuracy_o3 = evaluate_o3_assistant_accuracy(folder_path)\n",
    "    print(f\"The accuracy of quantitative value calculation after the logical reasoning is: {accuracy_4o:.2f}%\")\n",
    "    # print(f\"The accuracy of quantitative value calculation after the logical reasoning is: {accuracy_o3:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kn45Rri0ZvlV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPbFu8uClPdT5coNnyHuo/x",
   "gpuType": "T4",
   "mount_file_id": "1OTEgNhv2VIH5OFuAQzLVRD_nhP6w-tOo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
